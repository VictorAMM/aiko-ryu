# Mock Ollama Service

## Overview

The Mock Ollama Service is a comprehensive testing infrastructure that simulates the Ollama API for reliable, fast, and consistent testing without requiring a real Ollama instance.

## üéØ Purpose

The mock service was created to resolve testing issues where:
- Real Ollama API calls were causing timeouts
- Tests were failing due to network connectivity issues
- Test results were inconsistent due to external dependencies
- Development was blocked when Ollama server was unavailable

## üèóÔ∏è Architecture

### Core Components

#### **MockOllamaService** (`src/agents/MockOllamaService.ts`)
A singleton service that simulates all Ollama API endpoints:

```typescript
class MockOllamaService {
  // Core API methods
  generate(prompt: string, model?: string): Promise<MockOllamaResponse>
  generateStream(prompt: string, model?: string): Promise<ReadableStream>
  listModels(): Promise<MockOllamaModelsResponse>
  pull(model: string): Promise<MockOllamaResponse>
  
  // Utility methods
  reset(): void
  setDelay(ms: number): void
  setErrorRate(rate: number): void
}
```

#### **Mock Fetch Setup** (`test/mock-ollama-setup.ts`)
Test utilities that intercept global `fetch` calls and route them to the mock service:

```typescript
// Setup mock for tests
setupMockOllama()

// Teardown after tests
teardownMockOllama()
```

## üîß Features

### Realistic API Simulation
- **Model Management**: Simulates model listing, loading, and unloading
- **Text Generation**: Provides context-aware responses based on prompts
- **Streaming Support**: Simulates streaming responses for real-time testing
- **Error Handling**: Tests various error scenarios and recovery

### Context-Aware Responses
The mock service provides intelligent responses based on prompt content:

```typescript
// Example context-aware responses
"explain DDD" ‚Üí Detailed explanation of Domain-Driven Design
"test error" ‚Üí Simulated error response
"generate code" ‚Üí Sample code generation
"analyze data" ‚Üí Data analysis response
```

### Performance Testing
- **Configurable Delays**: Simulates realistic API response times
- **Timeout Testing**: Tests timeout scenarios and recovery
- **Concurrency Testing**: Handles multiple simultaneous requests

### State Management
- **Singleton Pattern**: Maintains consistent state across tests
- **Reset Capability**: Clean state between test runs
- **Model Tracking**: Tracks loaded/unloaded models

## üß™ Usage

### Basic Setup

```typescript
import { setupMockOllama, teardownMockOllama } from './test/mock-ollama-setup';

describe('Ollama Integration Tests', () => {
  beforeEach(() => {
    setupMockOllama();
  });

  afterEach(() => {
    teardownMockOllama();
  });

  test('should generate response', async () => {
    const sarah = new SarahAgent();
    const response = await sarah.generateResponse('explain DDD');
    expect(response).toBeDefined();
  });
});
```

### Advanced Configuration

```typescript
import { MockOllamaService } from '../src/agents/MockOllamaService';

// Configure mock behavior
const mockService = MockOllamaService.getInstance();
mockService.setDelay(100); // 100ms response delay
mockService.setErrorRate(0.1); // 10% error rate

// Test error scenarios
test('should handle API errors', async () => {
  mockService.setErrorRate(1.0); // Force errors
  const sarah = new SarahAgent();
  
  await expect(sarah.generateResponse('test')).rejects.toThrow();
});
```

## üìä Test Results

### Before Mock Service
- **Total Tests**: 156
- **Passing**: 128 (82% success rate)
- **Failing**: 28 (18% failure rate)
- **Main Issues**: Timeouts, network errors, inconsistent results

### After Mock Service
- **Total Tests**: 262
- **Passing**: 254 (97% success rate)
- **Failing**: 8 (3% failure rate)
- **Improvement**: 15% increase in success rate

## üîç Implementation Details

### Mock Response Types

```typescript
interface MockOllamaResponse {
  model: string;
  created_at: string;
  response: string;
  done: boolean;
  context?: number[];
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
  prompt_eval_duration?: number;
  eval_count?: number;
  eval_duration?: number;
}

interface MockOllamaModelsResponse {
  models: Array<{
    name: string;
    modified_at: string;
    size: number;
  }>;
}
```

### Fetch Interception

The mock setup intercepts global `fetch` calls and routes Ollama API calls to the mock service:

```typescript
const originalFetch = global.fetch;
global.fetch = async (input: RequestInfo | URL, init?: RequestInit) => {
  const url = typeof input === 'string' ? input : input.toString();
  
  if (url.includes('ollama') || url.includes('localhost:11434')) {
    return handleMockOllamaRequest(url, init);
  }
  
  return originalFetch(input, init);
};
```

## üöÄ Benefits

### Development Benefits
- **Faster Tests**: No network delays or timeouts
- **Consistent Results**: Predictable test outcomes
- **Offline Development**: Work without Ollama server
- **CI/CD Ready**: Reliable automated testing

### Quality Benefits
- **Error Testing**: Comprehensive error scenario coverage
- **Edge Case Testing**: Test timeout, network failure scenarios
- **Performance Testing**: Simulate various response times
- **Integration Testing**: Test full API integration paths

### Maintenance Benefits
- **Reduced Dependencies**: No external service requirements
- **Version Control**: Mock behavior is versioned with code
- **Documentation**: Mock serves as API documentation
- **Debugging**: Easy to debug test scenarios

## üîß Configuration

### Environment Variables
```bash
# Mock service configuration
MOCK_OLLAMA_DELAY=100
MOCK_OLLAMA_ERROR_RATE=0.0
MOCK_OLLAMA_ENABLED=true
```

### Test Configuration
```typescript
// jest.config.js
module.exports = {
  setupFilesAfterEnv: ['<rootDir>/test/mock-ollama-setup.ts'],
  testEnvironment: 'node',
  // ... other config
};
```

## üìà Future Enhancements

### Planned Features
- **Advanced Prompt Analysis**: More sophisticated context-aware responses
- **Model-Specific Behavior**: Different responses for different models
- **Performance Metrics**: Track mock service performance
- **Integration Tests**: Test mock with real Ollama comparison

### Potential Improvements
- **Dynamic Response Generation**: AI-powered mock responses
- **Scenario Testing**: Predefined test scenarios
- **Load Testing**: High-volume request simulation
- **Network Simulation**: Realistic network conditions

## ü§ù Contributing

### Adding New Mock Features
1. **Identify API Endpoint**: Determine which Ollama API to mock
2. **Implement Mock Logic**: Add method to `MockOllamaService`
3. **Add Tests**: Create tests for the new mock functionality
4. **Update Documentation**: Document the new feature

### Best Practices
- **Realistic Responses**: Mock responses should be realistic
- **Error Scenarios**: Include error handling tests
- **Performance**: Keep mock responses fast
- **Documentation**: Document all mock behaviors

## üìö Related Documentation

- [SarahAgent Documentation](./sarah.md) - Main agent using Ollama
- [Testing Guide](../dev/testing.md) - General testing practices
- [Ollama Integration](./ollama-integration.md) - Real Ollama integration
- [Development Workflow](../dev/development-workflow.md) - Development process

## üéØ Success Metrics

- **Test Reliability**: 97% success rate achieved
- **Development Velocity**: Faster test execution
- **CI/CD Stability**: Consistent automated testing
- **Developer Experience**: Reduced external dependencies

The Mock Ollama Service has significantly improved the testing infrastructure, making the development process more reliable and efficient while maintaining high test coverage and quality. 